"""
ç®—æ³•ç»“æœç¼“å­˜ç®¡ç†å™¨
ç”¨äºä¿å­˜å’ŒåŠ è½½ç®—æ³•è¿è¡Œç»“æœï¼Œé¿å…é‡å¤è®¡ç®—
"""

import pickle
import os
import hashlib
import json
from pathlib import Path


class AlgorithmCacheManager:
    """ç®—æ³•ç»“æœç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir="algorithm_cache"):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•è·¯å¾„
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.cache_index_file = self.cache_dir / "cache_index.json"
        self.cache_index = self._load_cache_index()
    
    def _load_cache_index(self):
        """åŠ è½½ç¼“å­˜ç´¢å¼•"""
        if self.cache_index_file.exists():
            with open(self.cache_index_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def _save_cache_index(self):
        """ä¿å­˜ç¼“å­˜ç´¢å¼•"""
        with open(self.cache_index_file, 'w', encoding='utf-8') as f:
            json.dump(self.cache_index, f, indent=2, ensure_ascii=False)
    
    def _generate_cache_key(self, algorithm_name, scene_id, params, experiment_group=None):
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            scene_id: åœºæ™¯ID
            params: ç®—æ³•å‚æ•°å­—å…¸
            experiment_group: å®éªŒç»„ç¼–å· (1=PSOå˜ä½“ç»„, 2=ç»å…¸ç®—æ³•ç»„)
        
        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        # æ¸…ç†ç®—æ³•åç§°ä¸­çš„éæ³•æ–‡ä»¶åå­—ç¬¦ï¼ˆWindows: < > : " / \ | ? *ï¼‰
        safe_algorithm_name = algorithm_name.replace('*', 'star').replace('/', '_').replace('\\', '_')
        safe_algorithm_name = safe_algorithm_name.replace(':', '_').replace('?', '_').replace('"', '_')
        safe_algorithm_name = safe_algorithm_name.replace('<', '_').replace('>', '_').replace('|', '_')
        
        # å°†å‚æ•°è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„å­—ç¬¦ä¸²
        param_str = json.dumps(params, sort_keys=True)
        param_hash = hashlib.md5(param_str.encode()).hexdigest()[:8]
        
        # æ·»åŠ å®éªŒç»„æ ‡è¯†
        if experiment_group is not None:
            group_suffix = f"_group{experiment_group}"
        else:
            group_suffix = ""
        
        return f"{safe_algorithm_name}_scene{scene_id}{group_suffix}_{param_hash}"
    
    def save_result(self, algorithm_name, scene_id, params, result_data, experiment_group=None):
        """
        ä¿å­˜ç®—æ³•ç»“æœ
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            scene_id: åœºæ™¯ID
            params: ç®—æ³•å‚æ•°å­—å…¸ (å¦‚ {'pop_size': 100, 'n_gen': 500, 'seed': 1})
            result_data: ç»“æœæ•°æ®å­—å…¸ (å¦‚ {'path': ..., 'costs': ..., 'time': ...})
            experiment_group: å®éªŒç»„ç¼–å· (1=PSOå˜ä½“ç»„, 2=ç»å…¸ç®—æ³•ç»„)
        """
        cache_key = self._generate_cache_key(algorithm_name, scene_id, params, experiment_group)
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        
        # ä¿å­˜ç»“æœæ•°æ®
        with open(cache_file, 'wb') as f:
            pickle.dump(result_data, f)
        
        # æ›´æ–°ç´¢å¼•
        self.cache_index[cache_key] = {
            'algorithm': algorithm_name,
            'scene_id': scene_id,
            'params': params,
            'file': str(cache_file),
            'timestamp': str(Path(cache_file).stat().st_mtime)
        }
        self._save_cache_index()
        
        print(f"  âœ… å·²ç¼“å­˜ {algorithm_name} çš„ç»“æœ: {cache_key}")
    
    def load_result(self, algorithm_name, scene_id, params, experiment_group=None):
        """
        åŠ è½½ç®—æ³•ç»“æœ
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            scene_id: åœºæ™¯ID
            params: ç®—æ³•å‚æ•°å­—å…¸
            experiment_group: å®éªŒç»„ç¼–å· (1=PSOå˜ä½“ç»„, 2=ç»å…¸ç®—æ³•ç»„)
        
        Returns:
            ç»“æœæ•°æ®å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        cache_key = self._generate_cache_key(algorithm_name, scene_id, params, experiment_group)
        
        if cache_key not in self.cache_index:
            return None
        
        cache_file = Path(self.cache_index[cache_key]['file'])
        
        if not cache_file.exists():
            print(f"  âš ï¸  ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
            return None
        
        try:
            with open(cache_file, 'rb') as f:
                result_data = pickle.load(f)
            print(f"  âœ… ä»ç¼“å­˜åŠ è½½ {algorithm_name} çš„ç»“æœ")
            return result_data
        except Exception as e:
            print(f"  âŒ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
            return None
    
    def has_cache(self, algorithm_name, scene_id, params, experiment_group=None):
        """
        æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼“å­˜
        
        Args:
            algorithm_name: ç®—æ³•åç§°
            scene_id: åœºæ™¯ID
            params: ç®—æ³•å‚æ•°å­—å…¸
            experiment_group: å®éªŒç»„ç¼–å· (1=PSOå˜ä½“ç»„, 2=ç»å…¸ç®—æ³•ç»„)
        
        Returns:
            Trueå¦‚æœå­˜åœ¨ç¼“å­˜ï¼Œå¦åˆ™False
        """
        cache_key = self._generate_cache_key(algorithm_name, scene_id, params, experiment_group)
        return cache_key in self.cache_index
    
    def clear_cache(self, algorithm_name=None, scene_id=None):
        """
        æ¸…é™¤ç¼“å­˜
        
        Args:
            algorithm_name: ç®—æ³•åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰
            scene_id: åœºæ™¯IDï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰åœºæ™¯
        """
        keys_to_remove = []
        
        for cache_key, info in self.cache_index.items():
            should_remove = True
            
            if algorithm_name is not None and info['algorithm'] != algorithm_name:
                should_remove = False
            
            if scene_id is not None and info['scene_id'] != scene_id:
                should_remove = False
            
            if should_remove:
                keys_to_remove.append(cache_key)
                cache_file = Path(info['file'])
                if cache_file.exists():
                    cache_file.unlink()
        
        for key in keys_to_remove:
            del self.cache_index[key]
        
        self._save_cache_index()
        print(f"  ğŸ—‘ï¸  å·²æ¸…é™¤ {len(keys_to_remove)} ä¸ªç¼“å­˜")
    
    def list_cache(self):
        """åˆ—å‡ºæ‰€æœ‰ç¼“å­˜"""
        print("\n" + "="*80)
        print(" ç¼“å­˜åˆ—è¡¨")
        print("="*80)
        
        if not self.cache_index:
            print("  (ç©º)")
            return
        
        for cache_key, info in self.cache_index.items():
            print(f"\nğŸ“¦ {cache_key}")
            print(f"   ç®—æ³•: {info['algorithm']}")
            print(f"   åœºæ™¯: Scene {info['scene_id']}")
            print(f"   å‚æ•°: {info['params']}")
            print(f"   æ–‡ä»¶: {info['file']}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
    cache_mgr = AlgorithmCacheManager()
    
    # ç¤ºä¾‹ï¼šä¿å­˜ç»“æœ
    params = {'pop_size': 100, 'n_gen': 500, 'seed': 1}
    result = {'path': [[1, 2, 3]], 'costs': [0.1, 0.2, 0.3, 0.4], 'time': 120.5}
    cache_mgr.save_result('PSO', 2, params, result)
    
    # ç¤ºä¾‹ï¼šåŠ è½½ç»“æœ
    loaded = cache_mgr.load_result('PSO', 2, params)
    print(f"åŠ è½½çš„ç»“æœ: {loaded}")
    
    # ç¤ºä¾‹ï¼šåˆ—å‡ºç¼“å­˜
    cache_mgr.list_cache()
    
    # ç¤ºä¾‹ï¼šæ¸…é™¤ç¼“å­˜
    # cache_mgr.clear_cache('PSO')  # æ¸…é™¤PSOçš„æ‰€æœ‰ç¼“å­˜
    # cache_mgr.clear_cache()  # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
